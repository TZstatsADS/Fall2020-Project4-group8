{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import math\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#if this doesn't run then do 'pip install causalinference' in command line\n",
    "from causalinference import CausalModel\n",
    "\n",
    "#if this doesn't run then do 'pip install rpy2' in command line\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "from rpy2.robjects import FloatVector, Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highDim_dataset = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1) Propensity Score Full Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mahalanobis Metric (Does not need propensity score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahalanobis distance is \n",
    "$$D_{ij} = (X_i-X_j)^T\\Sigma^{-1}(X_i-X_j)$$\n",
    "where $\\Sigma$ is the covariance matrix of $X$ in the pooled treatment and full control groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=lowDim_dataset.iloc[:,2:].values\n",
    "A=lowDim_dataset['A'].values\n",
    "Y=lowDim_dataset['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't need this anymore\n",
    "#dist_matrix_mahalanobis = pairwise_distances(X,metric='mahalanobis')\n",
    "\n",
    "#full matching:\n",
    "#fullmatch(match_on(A~X,data=lowDim_dataset,method='mahalanobis'),data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating gbm model for calculating propensity score\n",
    "\n",
    "gbm = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 2, min_samples_leaf = 1,\n",
    "                                min_samples_split = 2, n_estimators = 150).fit(X,A)\n",
    "\n",
    "propensity_scores = [x[1] for x in gbm.predict_proba(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_propensity = lowDim_dataset.copy(deep=True)\n",
    "lowDim_dataset_propensity['propensity_score'] = propensity_scores\n",
    "\n",
    "#full matching:\n",
    "#matchit(A~propensity_scores,data=lowDim_dataset_propensity,method='full')\n",
    "#OR\n",
    "#fullmatch(match_on(A~propensity_scores,data=lowDim_dataset_propensity,method='euclidean'),data=lowDim_dataset_propensity,method='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linear Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return math.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative values make sense since if you look at a graph of log(x/(1-x))\n",
    "linear_propensity_scores = [logit(x) for x in propensity_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_linear_propensity = lowDim_dataset.copy(deep=True)\n",
    "lowDim_dataset_linear_propensity['linear_propensity_score'] = linear_propensity_scores\n",
    "\n",
    "#full matching:\n",
    "#matchit(A~linear_propensity_scores,data=lowDim_dataset_linear_propensity,method='full')\n",
    "#OR\n",
    "##fullmatch(match_on(A~linear_propensity_scores,data=lowDim_dataset_linear_propensity,method='euclidean'),data=lowDim_dataset_linear_propensity,method='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low dim grid search (commented out since it takes a few minutes to run)\n",
    "\n",
    "#params = {'learning_rate':[0.01,0.05,0.1,0.5], 'max_depth': [1,2,3,4], 'n_estimators':[50,100,150],\n",
    "#          'min_samples_leaf':[1,3,5],'min_samples_split':[2,4,6]}\n",
    "#gscv = GridSearchCV(GradientBoostingClassifier(),params,cv=5).fit(X,A)\n",
    "#gscv.best_params_\n",
    "\n",
    "#output: {'learning_rate': 0.01,\n",
    "# 'max_depth': 2,\n",
    "# 'min_samples_leaf': 1,\n",
    "# 'min_samples_split': 2,\n",
    "# 'n_estimators': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high dim grid search (commented out since it takes a few minutes to run)\n",
    "\n",
    "#X=highDim_dataset.iloc[:,2:].values\n",
    "#A=highDim_dataset['A'].values\n",
    "#Y=highDim_dataset['Y'].values\n",
    "\n",
    "#params = {'learning_rate':[0.01,0.05,0.1,0.5], 'max_depth': [1,2,3,4], 'n_estimators':[50,100,150],\n",
    "#          'min_samples_leaf':[1,3,5],'min_samples_split':[2,4,6]}\n",
    "#gscv = GridSearchCV(GradientBoostingClassifier(),params,cv=5).fit(X,A)\n",
    "#gscv.best_params_\n",
    "\n",
    "\n",
    "#output: {'learning_rate': 0.05,\n",
    "# 'max_depth': 1,\n",
    "# 'min_samples_leaf': 5,\n",
    "# 'min_samples_split': 2,\n",
    "# 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Propensity Scores to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=lowDim_dataset.iloc[:,2:].values\n",
    "A=lowDim_dataset['A'].values\n",
    "Y=lowDim_dataset['Y'].values\n",
    "\n",
    "gbm = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 2, min_samples_leaf = 1,\n",
    "                                min_samples_split = 2, n_estimators = 150).fit(X,A)\n",
    "\n",
    "low_dim_propensity_scores = [x[1] for x in gbm.predict_proba(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=highDim_dataset.iloc[:,2:].values\n",
    "A=highDim_dataset['A'].values\n",
    "Y=highDim_dataset['Y'].values\n",
    "\n",
    "gbm = GradientBoostingClassifier(learning_rate = 0.05, max_depth = 1, min_samples_leaf = 5,\n",
    "                                min_samples_split = 2, n_estimators = 100).fit(X,A)\n",
    "\n",
    "high_dim_propensity_scores = [x[1] for x in gbm.predict_proba(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'propensity_scores':low_dim_propensity_scores}).to_csv('../output/low_dim_propensity_scores.csv')\n",
    "pd.DataFrame({'propensity_scores':high_dim_propensity_scores}).to_csv('../output/high_dim_propensity_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "packnames = ('optmatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmatch = rpackages.importr('optmatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    lowDim_dataset_R = robjects.conversion.py2rpy(lowDim_dataset)\n",
    "    lowDim_dataset_propensity_R = robjects.conversion.py2rpy(lowDim_dataset_propensity)\n",
    "    lowDim_dataset_linear_propensity_R = robjects.conversion.py2rpy(lowDim_dataset_linear_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>R/rpy2 DataFrame (6 x 25)</span>\n",
       "        <table>\n",
       "          <thead>\n",
       "            <tr>\n",
       "              \n",
       "              <th>Y</th>\n",
       "              \n",
       "              <th>A</th>\n",
       "              \n",
       "              <th>V1</th>\n",
       "              \n",
       "              <th>...</th>\n",
       "              \n",
       "              <th>V21</th>\n",
       "              \n",
       "              <th>V22</th>\n",
       "              \n",
       "              <th>propensity_score</th>\n",
       "              \n",
       "            </tr>\n",
       "          </thead>\n",
       "          <tbody>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              19.678858\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.590000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              ...\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.309683\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.405085\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              17.842989\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.719547\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.322207\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              22.108788\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              2.120000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.996210\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.298967\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              15.355899\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.504077\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.175873\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              16.787813\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.810000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.327864\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.159559\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              11.378754\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.405465\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.146625\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          </tbody>\n",
       "        </table>\n",
       "    "
      ],
      "text/plain": [
       "R object with classes: ('data.frame',) mapped to:\n",
       "[FloatSexp..., IntSexpVe..., FloatSexp..., FloatSexp..., ..., FloatSexp..., FloatSexp..., FloatSexp..., FloatSexp...]\n",
       "  Y: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[19.678858, 17.842989, 22.108788, 15.355899, 16.787813, 11.378754]\n",
       "  A: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[0, 0, 1, 0, 1, 0]\n",
       "  V1: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[1.590000, 0.000000, 0.000000, 0.000000, 1.810000, 0.000000]\n",
       "  V2: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]\n",
       "...\n",
       "  V4: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.980000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]\n",
       "  V5: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.000000, 0.000000, 2.120000, 0.000000, 0.000000, 0.000000]\n",
       "  V6: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[1.309683, 1.719547, 0.996210, 1.504077, 0.327864, 0.405465]\n",
       "  V7: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.405085, 0.322207, 0.298967, 0.175873, 0.159559, 0.146625]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.r.head(lowDim_dataset_propensity_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_match_propensity_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~propensity_score'),data=lowDim_dataset_propensity_R,method='euclidean'),data=lowDim_dataset_propensity_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above step, we can do the rest of the code in the implement_full_match.R using python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_propensity['assign'] = list(full_match_propensity_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>assign</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>18.392843</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.292125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>23.001812</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0.293804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y  A  assign  propensity_score\n",
       "185  18.392843  0      67          0.292125\n",
       "407  23.001812  1      67          0.293804"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example group\n",
    "lowDim_dataset_propensity.loc[lowDim_dataset_propensity['assign']==67][['Y','A','assign','propensity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_propensity_factor))):\n",
    "    temp = lowDim_dataset_propensity.loc[lowDim_dataset_propensity['assign']==i+1][['Y','A','assign','propensity_score']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_propensity_factor))):\n",
    "    temp = lowDim_dataset_propensity.loc[lowDim_dataset_propensity['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.387793812531444"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity_est_ATE=np.average(ATE_vec, weights=weights)\n",
    "propensity_est_ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
