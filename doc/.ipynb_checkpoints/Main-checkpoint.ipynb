{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Import Required Packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the cell below doesn't run then do 'pip install rpy2' or 'conda install -c r rpy2' and 'conda install tzlocal' in Anaconda Prompt\n",
    "#### Also, run pip install CausalInference or conda install -c conda-forge dowhy if you're using Anaconda Prompt\n",
    "#### Change the paths for os.environ below to match your R folder directory and version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"R_HOME\"] = r\"C:\\Program Files\\R\\R-4.0.2\"\n",
    "os.environ[\"PATH\"]   = r\"C:\\Program Files\\R\\R-4.0.2\\bin\\x64\" + \";\" + os.environ[\"PATH\"]\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "from rpy2.robjects import FloatVector, Formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pip install tabulate \n",
    "#### Run 'from causalinference import CausalModel' below if you used pip install, or 'from dowhy import CausalModel' if you used conda install above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "import math\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "from causalinference import CausalModel \n",
    "#from dowhy import CausalModel\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highDim_dataset = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Full Matching Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low dim grid search (commented out since it takes a few minutes to run)\n",
    "\n",
    "#X=lowDim_dataset.iloc[:,2:].values\n",
    "#A=lowDim_dataset['A'].values\n",
    "#Y=lowDim_dataset['Y'].values\n",
    "\n",
    "#params = {'learning_rate':[0.01,0.05,0.1,0.5], 'max_depth': [1,2,3,4], 'n_estimators':[50,100,150],\n",
    "#          'min_samples_leaf':[1,3,5],'min_samples_split':[2,4,6]}\n",
    "#gscv = GridSearchCV(GradientBoostingClassifier(),params,cv=5).fit(X,A)\n",
    "#gscv.best_params_\n",
    "\n",
    "#output: {'learning_rate': 0.01,\n",
    "# 'max_depth': 2,\n",
    "# 'min_samples_leaf': 1,\n",
    "# 'min_samples_split': 2,\n",
    "# 'n_estimators': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high dim grid search (commented out since it takes a few minutes to run)\n",
    "\n",
    "#X=highDim_dataset.iloc[:,2:].values\n",
    "#A=highDim_dataset['A'].values\n",
    "#Y=highDim_dataset['Y'].values\n",
    "\n",
    "#params = {'learning_rate':[0.01,0.05,0.1,0.5], 'max_depth': [1,2,3,4], 'n_estimators':[50,100,150],\n",
    "#          'min_samples_leaf':[1,3,5],'min_samples_split':[2,4,6]}\n",
    "#gscv = GridSearchCV(GradientBoostingClassifier(),params,cv=5).fit(X,A)\n",
    "#gscv.best_params_\n",
    "\n",
    "\n",
    "#output: {'learning_rate': 0.05,\n",
    "# 'max_depth': 1,\n",
    "# 'min_samples_leaf': 5,\n",
    "# 'min_samples_split': 2,\n",
    "# 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating Propensity and Linear Propensity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return math.log(x/(1-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Dimensional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=lowDim_dataset.iloc[:,2:].values\n",
    "A=lowDim_dataset['A'].values\n",
    "Y=lowDim_dataset['Y'].values\n",
    "\n",
    "gbm = GradientBoostingClassifier(learning_rate = 0.01, max_depth = 2, min_samples_leaf = 1,\n",
    "                                min_samples_split = 2, n_estimators = 150).fit(X,A)\n",
    "\n",
    "low_dim_propensity_scores = [x[1] for x in gbm.predict_proba(X)]\n",
    "low_dim_linear_propensity_scores = [logit(x) for x in low_dim_propensity_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_propensity = lowDim_dataset.copy(deep=True)\n",
    "lowDim_dataset_propensity['propensity_score'] = low_dim_propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_linear_propensity = lowDim_dataset.copy(deep=True)\n",
    "lowDim_dataset_linear_propensity['linear_propensity_score'] = low_dim_linear_propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'propensity_scores':low_dim_propensity_scores}).to_csv('../output/low_dim_propensity_scores.csv')\n",
    "pd.DataFrame({'linear_propensity_scores':low_dim_linear_propensity_scores}).to_csv('../output/low_dim_linear_propensity_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Dimensional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=highDim_dataset.iloc[:,2:].values\n",
    "A=highDim_dataset['A'].values\n",
    "Y=highDim_dataset['Y'].values\n",
    "\n",
    "gbm = GradientBoostingClassifier(learning_rate = 0.05, max_depth = 1, min_samples_leaf = 5,\n",
    "                                min_samples_split = 2, n_estimators = 100).fit(X,A)\n",
    "\n",
    "high_dim_propensity_scores = [x[1] for x in gbm.predict_proba(X)]\n",
    "high_dim_linear_propensity_scores = [logit(x) for x in high_dim_propensity_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "highDim_dataset_propensity = highDim_dataset.copy(deep=True)\n",
    "highDim_dataset_propensity['propensity_score'] = high_dim_propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "highDim_dataset_linear_propensity = highDim_dataset.copy(deep=True)\n",
    "highDim_dataset_linear_propensity['linear_propensity_score'] = high_dim_linear_propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'propensity_scores':high_dim_propensity_scores}).to_csv('../output/high_dim_propensity_scores.csv')\n",
    "pd.DataFrame({'linear_propensity_scores':high_dim_linear_propensity_scores}).to_csv('../output/high_dim_linear_propensity_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform Full Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True ATE: 2.5 for low dim and -3 for high dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up rpy2 (Python Interface to R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# utils = rpackages.importr('utils')\n",
    "utils = importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "packnames = ('optmatch')\n",
    "#utils.install_packages('DirichletReg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing packages into 'C:/Users/Elise Nguyen/OneDrive/Documents/R/win-library/4.0'\n",
      "(as 'lib' is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "utils.chooseCRANmirror(ind=1)\n",
    "robjects.r(f'install.packages(\"{\"optmatch\"}\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmatch = rpackages.importr('optmatch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Low Dimensional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    try:\n",
    "        lowDim_R_runtime = time.time()\n",
    "        lowDim_dataset_R = robjects.conversion.py2rpy(lowDim_dataset)\n",
    "        lowDim_R_runtime = time.time()-lowDim_R_runtime\n",
    "        \n",
    "        lowDim_propensity_R_runtime = time.time()\n",
    "        lowDim_dataset_propensity_R = robjects.conversion.py2rpy(lowDim_dataset_propensity)\n",
    "        lowDim_propensity_R_runtime = time.time()-lowDim_propensity_R_runtime\n",
    "        \n",
    "        lowDim_linear_propensity_R_runtime = time.time()\n",
    "        lowDim_dataset_linear_propensity_R = robjects.conversion.py2rpy(lowDim_dataset_linear_propensity)\n",
    "        lowDim_linear_propensity_R_runtime = time.time()-lowDim_linear_propensity_R_runtime\n",
    "        \n",
    "    except:\n",
    "        lowDim_R_runtime = time.time()\n",
    "        lowDim_dataset_R = pandas2ri.py2ri(lowDim_dataset)\n",
    "        lowDim_R_runtime = time.time()-lowDim_R_runtime\n",
    "        \n",
    "        lowDim_propensity_R_runtime = time.time()\n",
    "        lowDim_dataset_propensity_R = pandas2ri.py2ri(lowDim_dataset_propensity)\n",
    "        lowDim_propensity_R_runtime = time.time()-lowDim_propensity_R_runtime\n",
    "        \n",
    "        lowDim_linear_propensity_R_runtime = time.time()\n",
    "        lowDim_dataset_linear_propensity_R = pandas2ri.py2ri(lowDim_dataset_linear_propensity)\n",
    "        lowDim_linear_propensity_R_runtime = time.time()-lowDim_linear_propensity_R_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>R/rpy2 DataFrame (6 x 25)</span>\n",
       "        <table>\n",
       "          <thead>\n",
       "            <tr>\n",
       "              \n",
       "              <th>Y</th>\n",
       "              \n",
       "              <th>A</th>\n",
       "              \n",
       "              <th>V1</th>\n",
       "              \n",
       "              <th>...</th>\n",
       "              \n",
       "              <th>V21</th>\n",
       "              \n",
       "              <th>V22</th>\n",
       "              \n",
       "              <th>propensity_score</th>\n",
       "              \n",
       "            </tr>\n",
       "          </thead>\n",
       "          <tbody>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              19.678858\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.590000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              ...\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.309683\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.405085\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              17.842989\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.719547\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.322207\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              22.108788\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              2.120000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.996210\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.298967\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              15.355899\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.504077\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.175873\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              16.787813\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1.810000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.327864\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.159559\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              11.378754\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.000000\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.405465\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.146625\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          </tbody>\n",
       "        </table>\n",
       "    "
      ],
      "text/plain": [
       "R object with classes: ('data.frame',) mapped to:\n",
       "[FloatSexp..., IntSexpVe..., FloatSexp..., FloatSexp..., ..., FloatSexp..., FloatSexp..., FloatSexp..., FloatSexp...]\n",
       "  Y: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[19.678858, 17.842989, 22.108788, 15.355899, 16.787813, 11.378754]\n",
       "  A: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[0, 0, 1, 0, 1, 0]\n",
       "  V1: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[1.590000, 0.000000, 0.000000, 0.000000, 1.810000, 0.000000]\n",
       "  V2: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]\n",
       "...\n",
       "  V4: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.980000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]\n",
       "  V5: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.000000, 0.000000, 2.120000, 0.000000, 0.000000, 0.000000]\n",
       "  V6: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[1.309683, 1.719547, 0.996210, 1.504077, 0.327864, 0.405465]\n",
       "  V7: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.405085, 0.322207, 0.298967, 0.175873, 0.159559, 0.146625]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.r.head(lowDim_dataset_propensity_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahalanobis distance is \n",
    "$$D_{ij} = (X_i-X_j)^T\\Sigma^{-1}(X_i-X_j)$$\n",
    "where $\\Sigma$ is the covariance matrix of $X$ in the pooled treatment and full control groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "full_match_Mahalanobis_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~.-Y'),data=lowDim_dataset_R,method='mahalanobis'),data=lowDim_dataset_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset['assign'] = list(full_match_Mahalanobis_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_Mahalanobis_factor))):\n",
    "    temp = lowDim_dataset.loc[lowDim_dataset['assign']==i+1][['Y','A','assign']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_Mahalanobis_factor))):\n",
    "    temp = lowDim_dataset.loc[lowDim_dataset['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "\n",
    "Mahalanobis_lowDim_est_ATE = np.average(ATE_vec, weights = weights)\n",
    "\n",
    "end = time.time()\n",
    "lowDim_mahalanobis_match_runtime = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.895'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#runtime is time to convert to R data frame + time to do matching\n",
    "lowDim_mahalanobis_runtime = \"{:,.3f}\".format(lowDim_R_runtime+lowDim_mahalanobis_match_runtime)\n",
    "lowDim_mahalanobis_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.906\n"
     ]
    }
   ],
   "source": [
    "Mahalanobis_lowDim_est_ATE =\"{:,.3f}\".format(Mahalanobis_lowDim_est_ATE)\n",
    "print(Mahalanobis_lowDim_est_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "full_match_propensity_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~propensity_score'),data=lowDim_dataset_propensity_R,method='euclidean'),data=lowDim_dataset_propensity_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above step, we can do the rest of the code in the implement_full_match.R using python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_propensity['assign'] = list(full_match_propensity_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>assign</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>18.392843</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.292125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>23.001812</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0.293804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y  A  assign  propensity_score\n",
       "185  18.392843  0      67          0.292125\n",
       "407  23.001812  1      67          0.293804"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example group\n",
    "lowDim_dataset_propensity.loc[lowDim_dataset_propensity['assign']==67][['Y','A','assign','propensity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_propensity_factor))):\n",
    "    temp = lowDim_dataset_propensity.loc[lowDim_dataset_propensity['assign']==i+1][['Y','A','assign','propensity_score']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_propensity_factor))):\n",
    "    temp = lowDim_dataset_propensity.loc[lowDim_dataset_propensity['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "\n",
    "lowDim_propensity_est_ATE = np.average(ATE_vec, weights=weights)\n",
    "    \n",
    "end = time.time()\n",
    "lowDim_propensity_match_runtime = end-start\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.250'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowDim_propensity_runtime = \"{:,.3f}\".format(lowDim_propensity_R_runtime+lowDim_propensity_match_runtime)\n",
    "lowDim_propensity_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.388\n"
     ]
    }
   ],
   "source": [
    "lowDim_propensity_est_ATE = \"{:,.3f}\".format(lowDim_propensity_est_ATE)\n",
    "print(lowDim_propensity_est_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Linear Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "full_match_linear_propensity_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~linear_propensity_score'),data=lowDim_dataset_linear_propensity_R,method='euclidean'),data=lowDim_dataset_linear_propensity_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset_linear_propensity['assign'] = list(full_match_linear_propensity_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>assign</th>\n",
       "      <th>linear_propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20.359007</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.019142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>19.588519</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.029623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>16.301866</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.011693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>15.106868</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.036838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>17.005677</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.025284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>26.525997</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>16.718287</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.031649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>21.382709</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.037664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y  A  assign  linear_propensity_score\n",
       "43   20.359007  1      67                -1.019142\n",
       "58   19.588519  0      67                -1.029623\n",
       "106  16.301866  0      67                -1.011693\n",
       "126  15.106868  0      67                -1.036838\n",
       "160  17.005677  0      67                -1.025284\n",
       "217  26.525997  0      67                -1.000699\n",
       "308  16.718287  0      67                -1.031649\n",
       "371  21.382709  0      67                -1.037664"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example group\n",
    "lowDim_dataset_linear_propensity.loc[lowDim_dataset_linear_propensity['assign']==67][['Y','A','assign','linear_propensity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_linear_propensity_factor))):\n",
    "    temp = lowDim_dataset_linear_propensity.loc[lowDim_dataset_linear_propensity['assign']==i+1][['Y','A','assign','linear_propensity_score']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_linear_propensity_factor))):\n",
    "    temp = lowDim_dataset_linear_propensity.loc[lowDim_dataset_linear_propensity['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "\n",
    "lowDim_linear_propensity_est_ATE = np.average(ATE_vec, weights=weights)\n",
    "\n",
    "end = time.time()\n",
    "lowDim_linear_propensity_match_runtime = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.940'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowDim_linear_propensity_runtime = \"{:,.3f}\".format(lowDim_linear_propensity_R_runtime+lowDim_linear_propensity_match_runtime)\n",
    "lowDim_linear_propensity_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_linear_propensity_est_ATE = \"{:,.3f}\".format(lowDim_linear_propensity_est_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. High Dimensional Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "    try:\n",
    "        highDim_R_runtime = time.time()\n",
    "        highDim_dataset_R = robjects.conversion.py2rpy(highDim_dataset)\n",
    "        highDim_R_runtime = time.time()-highDim_R_runtime\n",
    "        \n",
    "        highDim_propensity_R_runtime = time.time()\n",
    "        highDim_dataset_propensity_R = robjects.conversion.py2rpy(highDim_dataset_propensity)\n",
    "        highDim_propensity_R_runtime = time.time()-highDim_propensity_R_runtime\n",
    "        \n",
    "        highDim_linear_propensity_R_runtime = time.time()\n",
    "        highDim_dataset_linear_propensity_R = robjects.conversion.py2rpy(highDim_dataset_linear_propensity)\n",
    "        highDim_linear_propensity_R_runtime = time.time()-highDim_linear_propensity_R_runtime\n",
    "        \n",
    "    except:\n",
    "        highDim_R_runtime = time.time()\n",
    "        highDim_dataset_R = pandas2ri.py2ri(highDim_dataset)\n",
    "        highDim_R_runtime = time.time()-highDim_R_runtime\n",
    "        \n",
    "        highDim_propensity_R_runtime = time.time()\n",
    "        highDim_dataset_propensity_R = pandas2ri.py2ri(highDim_dataset_propensity)\n",
    "        highDim_propensity_R_runtime = time.time()-highDim_propensity_R_runtime\n",
    "        \n",
    "        highDim_linear_propensity_R_runtime = time.time()\n",
    "        highDim_dataset_linear_propensity_R = pandas2ri.py2ri(highDim_dataset_linear_propensity)\n",
    "        highDim_linear_propensity_R_runtime = time.time()-highDim_linear_propensity_R_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>R/rpy2 DataFrame (6 x 188)</span>\n",
       "        <table>\n",
       "          <thead>\n",
       "            <tr>\n",
       "              \n",
       "              <th>Y</th>\n",
       "              \n",
       "              <th>A</th>\n",
       "              \n",
       "              <th>V1</th>\n",
       "              \n",
       "              <th>...</th>\n",
       "              \n",
       "              <th>V184</th>\n",
       "              \n",
       "              <th>V185</th>\n",
       "              \n",
       "              <th>propensity_score</th>\n",
       "              \n",
       "            </tr>\n",
       "          </thead>\n",
       "          <tbody>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              -11.682472\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              ...\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.503957\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              -13.176546\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.431710\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              -2.195401\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.574668\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              -0.005454\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -10\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -10\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.465927\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              -1.987538\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -10\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              -10\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.549626\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          <tr>\n",
       "            \n",
       "            <td>\n",
       "              -17.810820\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              1\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              \n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              8\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              5\n",
       "            </td>\n",
       "            \n",
       "            <td>\n",
       "              0.465929\n",
       "            </td>\n",
       "            \n",
       "          </tr>\n",
       "          \n",
       "          </tbody>\n",
       "        </table>\n",
       "    "
      ],
      "text/plain": [
       "R object with classes: ('data.frame',) mapped to:\n",
       "[FloatSexp..., IntSexpVe..., IntSexpVe..., IntSexpVe..., ..., IntSexpVe..., IntSexpVe..., IntSexpVe..., FloatSexp...]\n",
       "  Y: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[-11.682472, -13.176546, -2.195401, -0.005454, -1.987538, -17.810820]\n",
       "  A: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[1, 0, 1, 1, 1, 1]\n",
       "  V1: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[0, 1, 0, 1, 1, 1]\n",
       "  V2: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[1, 1, 1, 1, 1, 0]\n",
       "...\n",
       "  V4: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[-1, -1, -1, -10, -10, 7]\n",
       "  V5: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[-1, -1, -1, -10, -10, 8]\n",
       "  V6: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('RTYPES.INTSXP',) mapped to:\n",
       "[-1, -1, -1, -10, -10, 5]\n",
       "  V7: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "[0.503957, 0.431710, 0.574668, 0.465927, 0.549626, 0.465929]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.r.head(highDim_dataset_propensity_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "full_match_Mahalanobis_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~.-Y'),data=highDim_dataset_R,method='mahalanobis'),data=highDim_dataset_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "highDim_dataset['assign'] = list(full_match_Mahalanobis_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_Mahalanobis_factor))):\n",
    "    temp = highDim_dataset.loc[highDim_dataset['assign']==i+1][['Y','A','assign']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_Mahalanobis_factor))):\n",
    "    temp = highDim_dataset.loc[highDim_dataset['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "    \n",
    "highDim_Mahalanobis_est_ATE = np.average(ATE_vec, weights=weights)\n",
    "    \n",
    "end = time.time()\n",
    "highDim_mahalanobis_match_runtime = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95.694'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highDim_mahalanobis_runtime = \"{:,.3f}\".format(highDim_R_runtime+highDim_mahalanobis_match_runtime)\n",
    "highDim_mahalanobis_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.553\n"
     ]
    }
   ],
   "source": [
    "highDim_Mahalanobis_est_ATE= \"{:,.3f}\".format(highDim_Mahalanobis_est_ATE)\n",
    "print(highDim_Mahalanobis_est_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "full_match_propensity_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~propensity_score'),data=highDim_dataset_propensity_R,method='euclidean'),data=highDim_dataset_propensity_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "highDim_dataset_propensity['assign'] = list(full_match_propensity_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_propensity_factor))):\n",
    "    temp = highDim_dataset_propensity.loc[highDim_dataset_propensity['assign']==i+1][['Y','A','assign','propensity_score']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_propensity_factor))):\n",
    "    temp = highDim_dataset_propensity.loc[highDim_dataset_propensity['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "\n",
    "highDim_propensity_est_ATE = np.average(ATE_vec, weights=weights)    \n",
    "\n",
    "end = time.time()\n",
    "highDim_propensity_match_runtime = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.151'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highDim_propensity_runtime = \"{:,.3f}\".format(highDim_propensity_R_runtime+highDim_propensity_match_runtime)\n",
    "highDim_propensity_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.292\n"
     ]
    }
   ],
   "source": [
    "highDim_propensity_est_ATE = \"{:,.3f}\".format(highDim_propensity_est_ATE)\n",
    "print(highDim_propensity_est_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Linear Propensity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "full_match_linear_propensity_factor = optmatch.fullmatch(optmatch.match_on(Formula('A~linear_propensity_score'),data=highDim_dataset_linear_propensity_R,\n",
    "                                                                           method='euclidean'),data=highDim_dataset_linear_propensity_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "highDim_dataset_linear_propensity['assign'] = list(full_match_linear_propensity_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#if this doesn't print anything then that means each group has at least one control and at least one treatment which is good\n",
    "\n",
    "for i in range(max(list(full_match_linear_propensity_factor))):\n",
    "    temp = highDim_dataset_linear_propensity.loc[highDim_dataset_linear_propensity['assign']==i+1][['Y','A','assign','linear_propensity_score']]\n",
    "    grouping = temp['A'].values\n",
    "    \n",
    "    if (sum(grouping)==0 or sum(grouping)==len(grouping)):\n",
    "        print(i+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute ATE\n",
    "ATE_vec = []\n",
    "weights = []\n",
    "\n",
    "for i in range(max(list(full_match_linear_propensity_factor))):\n",
    "    temp = highDim_dataset_linear_propensity.loc[highDim_dataset_linear_propensity['assign']==i+1]\n",
    "    \n",
    "    treatment_Y = temp.loc[temp['A']==1]['Y'].values\n",
    "    control_Y = temp.loc[temp['A']==0]['Y'].values\n",
    "    \n",
    "    ATE_vec.append(np.mean(treatment_Y)-np.mean(control_Y))\n",
    "    weights.append(len(treatment_Y)+len(control_Y))\n",
    "    \n",
    "highDim_linear_propensity_est_ATE=np.average(ATE_vec, weights=weights)\n",
    "\n",
    "end = time.time()\n",
    "highDim_linear_propensity_match_runtime = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.847'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highDim_linear_propensity_runtime = \"{:,.3f}\".format(highDim_linear_propensity_R_runtime+highDim_linear_propensity_match_runtime)\n",
    "highDim_linear_propensity_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.232\n"
     ]
    }
   ],
   "source": [
    "highDim_linear_propensity_est_ATE= \"{:,.3f}\".format(highDim_linear_propensity_est_ATE)\n",
    "print(highDim_linear_propensity_est_ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inverse Propensity Weighting Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reset data & Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highDim_dataset = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipw_ate(dataset):\n",
    "    treated = 0\n",
    "    controlled = 0\n",
    "    for i in range(dataset.shape[0]):\n",
    "        if dataset['A'][i] == 1:\n",
    "            treated += dataset['Y'][i] * dataset['weight'][i]\n",
    "        else:\n",
    "            controlled += dataset['Y'][i] * dataset['weight'][i]\n",
    "\n",
    "    print(treated - controlled)\n",
    "    ate = (treated - controlled)/dataset.shape[0]\n",
    "    return ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_params(X, A, params, dataset):\n",
    "    runtime = time.time()\n",
    "    gscv = GridSearchCV(GradientBoostingClassifier(),params,cv=5).fit(X, A)\n",
    "    print('best_param: ', gscv.best_params_)\n",
    "    print('best_score: ', gscv.best_score_)\n",
    "    gbm_best = gscv.best_estimator_\n",
    "    gbm_best.fit(X, A)\n",
    "    propensity_new = [x[1] for x in gbm_best.predict_proba(X)]\n",
    "    dataset_temp = dataset\n",
    "    dataset_temp['score'] = propensity_new\n",
    "    dataset_temp['weight'] = dataset_temp['A']/dataset_temp['score'] + (1 - dataset_temp['A'])/(1 - dataset_temp['score'])\n",
    "    runtime = time.time()-runtime\n",
    "    runtime_str = \"{:,.3f}\".format(runtime)\n",
    "    print('runtime: ', runtime_str )\n",
    "    return dataset_temp, runtime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Low Dim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_param:  {'learning_rate': 0.05, 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "best_score:  0.7642105263157896\n",
      "runtime:  69.045\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':[0.001,0.01,0.05,0.1], 'max_depth': [1,2,3], 'n_estimators':[50,100,200],\n",
    "          'min_samples_leaf':[1,2],'min_samples_split':[2,4]}\n",
    "X=lowDim_dataset.iloc[:,2:].values\n",
    "A=lowDim_dataset['A'].values\n",
    "dataset_test, runtime = train_params(X, A, params, lowDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852.5985560478684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.795'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate_low = \"{:,.3f}\".format(ipw_ate(dataset_test))\n",
    "ate_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. High Dim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_param:  {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "best_score:  0.595\n",
      "runtime:  689.278\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':[0.05,0.1,0.5,1], 'max_depth': [1,2,3], 'n_estimators':[50,100,150],\n",
    "          'min_samples_leaf':[1,2],'min_samples_split':[2]}\n",
    "X=highDim_dataset.iloc[:,2:].values\n",
    "A=highDim_dataset['A'].values\n",
    "dataset_test_high, runtime_high = train_params(X, A, params, highDim_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4105.192745053388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-2.053'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate_high = \"{:,.3f}\".format(ipw_ate(dataset_test_high))\n",
    "ate_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowDim_dataset = pd.read_csv('../data/lowDim_dataset.csv')\n",
    "highDim_dataset = pd.read_csv('../data/highDim_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Low Dim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = lowDim_dataset['Y']\n",
    "D = lowDim_dataset['A']\n",
    "X = lowDim_dataset.iloc[:,2:].values\n",
    "N = lowDim_dataset.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratification Summary\n",
      "\n",
      "              Propensity Score         Sample Size     Ave. Propensity   Outcome\n",
      "   Stratum      Min.      Max.  Controls   Treated  Controls   Treated  Raw-diff\n",
      "--------------------------------------------------------------------------------\n",
      "         1     0.001     0.995       363       112     0.184     0.404     4.994\n",
      "\n",
      "\n",
      "Treatment Effect Estimates: Blocking\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE      2.467      0.113     21.793      0.000      2.246      2.689\n",
      "           ATC      2.467      0.113     21.793      0.000      2.246      2.689\n",
      "           ATT      2.467      0.113     21.793      0.000      2.246      2.689\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\elise nguyen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\causalinference\\estimators\\ols.py:21: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  olscoef = np.linalg.lstsq(Z, Y)[0]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cm = CausalModel(Y=Y, D=D, X=X)\n",
    "    \n",
    "cm.est_propensity_s()\n",
    "cm.stratify_s()\n",
    "print(cm.strata)\n",
    "cm.est_via_blocking()\n",
    "print(cm.estimates)\n",
    "end = time.time()\n",
    "lowdim_strat_runtime = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.955\n"
     ]
    }
   ],
   "source": [
    "lowdim_strat_runtime = \"{:,.3f}\".format(lowdim_strat_runtime)\n",
    "print(lowdim_strat_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. High Dim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = highDim_dataset['Y']\n",
    "D = highDim_dataset['A']\n",
    "X = highDim_dataset.iloc[:,2:].values\n",
    "N = highDim_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratification Summary\n",
      "\n",
      "              Propensity Score         Sample Size     Ave. Propensity   Outcome\n",
      "   Stratum      Min.      Max.  Controls   Treated  Controls   Treated  Raw-diff\n",
      "--------------------------------------------------------------------------------\n",
      "         1     0.045     0.431       707       294     0.276     0.326    -2.362\n",
      "         2     0.431     0.996       396       603     0.570     0.630    -1.843\n",
      "\n",
      "\n",
      "Treatment Effect Estimates: Blocking\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE     -2.948      0.047    -63.044      0.000     -3.039     -2.856\n",
      "           ATC     -2.939      0.050    -58.573      0.000     -3.037     -2.840\n",
      "           ATT     -2.959      0.047    -62.347      0.000     -3.052     -2.866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\elise nguyen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\causalinference\\estimators\\ols.py:21: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  olscoef = np.linalg.lstsq(Z, Y)[0]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cm = CausalModel(Y=Y, D=D, X=X)\n",
    "cm.est_propensity_s()\n",
    "cm.stratify_s()\n",
    "print(cm.strata)\n",
    "cm.est_via_blocking()\n",
    "print(cm.estimates)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,966.204\n"
     ]
    }
   ],
   "source": [
    "highdim_strat_runtime=\"{:,.3f}\".format(end-start)\n",
    "print(highdim_strat_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Metric          </th><th>Dimension  </th><th>Full Matching-\n",
       "Mahalanobis       </th><th>Full Matching-\n",
       "Propensity score       </th><th>Full Matching-\n",
       "Linear Propensity Score       </th><th>Inverse Propensity\n",
       "Weighting        </th><th>Stratification  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Best ATE score  </td><td>Low Dim    </td><td>2.906 </td><td>3.388 </td><td>3.476 </td><td>1.795  </td><td>2.467           </td></tr>\n",
       "<tr><td>                </td><td>High Dim   </td><td>-1.553</td><td>-3.292</td><td>-3.232</td><td>-2.053 </td><td>2.467           </td></tr>\n",
       "<tr><td>Run Time (sec)  </td><td>Low Dim    </td><td>0.583 </td><td>2.736 </td><td>2.306 </td><td>69.045 </td><td>3.955           </td></tr>\n",
       "<tr><td>                </td><td>High Dim   </td><td>75.963</td><td>7.232 </td><td>7.633 </td><td>689.278</td><td>1,966.204       </td></tr>\n",
       "<tr><td>Computer Used   </td><td>           </td><td>PC    </td><td>PC    </td><td>PC    </td><td>PC     </td><td>PC              </td></tr>\n",
       "<tr><td>Stable/Nonstable</td><td>           </td><td>Stable</td><td>Stable</td><td>Stable</td><td>Stable </td><td>Stable          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = [[\"Best ATE score\",'Low Dim',Mahalanobis_lowDim_est_ATE,lowDim_propensity_est_ATE,\n",
    "          lowDim_linear_propensity_est_ATE,ate_low,2.467],\n",
    "        [\"\",'High Dim',highDim_Mahalanobis_est_ATE,highDim_propensity_est_ATE,\n",
    "          highDim_linear_propensity_est_ATE,ate_high,2.467],\n",
    "        [\"Run Time (sec)\",'Low Dim',lowDim_mahalanobis_runtime,lowDim_propensity_runtime,lowDim_linear_propensity_runtime,\n",
    "         runtime,lowdim_strat_runtime],\n",
    "        [\"\",'High Dim',highDim_mahalanobis_runtime,highDim_propensity_runtime,highDim_linear_propensity_runtime,\n",
    "         runtime_high,highdim_strat_runtime],\n",
    "        [\"Computer Used\",'','PC','PC','PC','PC','PC'],\n",
    "        [\"Stable/Nonstable\",'','Stable','Stable','Stable','Stable','Stable']]\n",
    "\n",
    "display(HTML(tabulate.tabulate(table, headers=[\"Metric\",\"Dimension\", \"Full Matching-\\nMahalanobis\",\n",
    "                                               \"Full Matching-\\nPropensity score\", \"Full Matching-\\nLinear Propensity Score\",\n",
    "                                               \"Inverse Propensity\\nWeighting\", 'Stratification'],\n",
    "                                tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://projecteuclid.org/download/pdfview_1/euclid.ss/1280841730\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36552.pdf\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5784842/\n",
    "https://www.researchgate.net/publication/8132035_Propensity_Score_Estimation_With_Boosted_Regression_for_Evaluating_Causal_Effects_in_Observational_Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
